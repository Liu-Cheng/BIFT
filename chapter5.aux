\relax 
\citation{fink2019deep,tzelepi2017human}
\citation{esteva2019guide}
\citation{banerjee2019towards,jha2019ml}
\citation{jenihhin2019challenges}
\citation{chen2014dadiannao}
\citation{xu2020hybrid,reagen2016minerva}
\citation{impact2011dixit}
\citation{mittal2020survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Fault-Tolerant Deep Learning Processors}{211}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction to Fault-Tolerant Deep Learning}{211}{}\protected@file@percent }
\citation{7551380,7551379}
\citation{6193402}
\citation{7551380}
\citation{7551379}
\citation{7987496}
\citation{7879109}
\citation{7987496}
\citation{Chen2016Eyeriss}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Deep Learning Processor Basis}{212}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1.1}Typical 2D-Array Based Deep Learning Accelerator}{212}{}\protected@file@percent }
\citation{7551380,7920854}
\citation{Liu:2019:FTN:3287624.3288743}
\citation{Li:2017:UEP:3126908.3126964,xu2020hybrid,xu2021reliability}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A typical DLA with 2D computing array architecture.}}{213}{}\protected@file@percent }
\newlabel{fig:accelerator}{{5.1}{213}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1.2} ReRAM-based DNN Computing}{213}{}\protected@file@percent }
\citation{8715178}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces (a) The analog dot-product computing mechanism of ReRAM. (b) A simple mapping scheme of input feature maps and kernels.}}{214}{}\protected@file@percent }
\newlabel{fig:reramcomputing}{{5.2}{214}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1.3}Neural Network Training Basis}{214}{}\protected@file@percent }
\citation{mittal2020survey}
\citation{xu2021reliability}
\citation{xu2020persistent}
\citation{ning2020ftt}
\citation{zhang2019fault}
\newlabel{eq:backforward}{{5.3}{215}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces An illustration of the training process of a full-connected neural network.}}{215}{}\protected@file@percent }
\newlabel{fig:networktraining}{{5.3}{215}}[\bf Example\,]
\citation{error2018date}
\citation{energy2018kim}
\citation{axtrain2018he}
\citation{xu2019resilient}
\citation{li2019squeezing}
\citation{wang2017resilience}
\citation{axtrain2018he}
\citation{zhang2018analyzing}
\citation{zhang2019fault}
\citation{abdullah2020salvagednn}
\citation{takanami2017built}
\citation{takanami2012built}
\citation{horita2000fault}
\citation{stapper1983integrated}
\citation{ozen2019sanity}
\citation{zhao2020algorithm}
\citation{zhang2020sorting}
\citation{li2020soft}
\citation{mahdiani2012relaxed}
\citation{6165062}
\citation{6725492}
\citation{8119491}
\citation{ning2020ftt}
\citation{7926952}
\citation{jouppi2017datacenter,Chen2016Eyeriss}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Challenges of Fault-Tolerant Deep Learning}{217}{}\protected@file@percent }
\citation{deng2015retraining,zhang2019fault,xu2019resilient,li2019squeezing}
\citation{validation2019Ebert}
\citation{7167198}
\citation{5726731}
\citation{6725492}
\citation{takanami2012built}
\citation{takanami2017built}
\citation{mittal2020survey}
\citation{neggaz2018reliability}
\citation{ares2018dac}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Fault-Tolerant Deep Learning Architecture}{219}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Deep Learning Sensitivity to Hardware Faults}{219}{}\protected@file@percent }
\newlabel{sec:eqerror}{{5.2.1}{219}}[\bf Example\,]
\newlabel{eq:error_rate}{{5.4}{219}}[\bf Example\,]
\citation{Chen2016Eyeriss}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Prediction accuracy of Resenet18 executed on a typical DLA under different PER setups. For each PER setup, 50 random fault configurations are evaluated on ImageNet.}}{220}{}\protected@file@percent }
\newlabel{fig:bit}{{5.4}{220}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces The fully functional probability of the 2-D computing array under different PER setups.}}{220}{}\protected@file@percent }
\newlabel{fig:mo}{{5.5}{220}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Recomputing Based Hybrid Computing Architecture}{220}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Overview of of a DLA with Hybrid Computing Architecture. The components highlighted with blue are added to the conventional DLA to tolerate faulty PEs in arbitrary locations of the 2-D computing array.}}{221}{}\protected@file@percent }
\newlabel{fig:mapping}{{5.6}{221}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces The dataflow of using DPPU for recomputing the neural network operations mapped on the faulty PEs of a typical DLA. It also demonstrates how the DPPU overwrites the faulty computing results produced by the 2-D computing array.}}{222}{}\protected@file@percent }
\newlabel{fig:pipeline}{{5.7}{222}}[\bf Example\,]
\newlabel{sec:dataflow}{{5.2.2}{223}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}HyCA Micro-architecture}{225}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Structures of the unified DPPU and the grouped DPPU. For both the unified DPPU and the grouped DPPU, they are protected with redundant PEs. Each redundant PE is used to protect a set of homogeneous PEs and these PEs are connected with ring topology to reduce the signal fan-out.}}{225}{}\protected@file@percent }
\newlabel{fig:deg}{{5.8}{225}}[\bf Example\,]
\citation{Energy2003Aneesh,A2012Chang}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Organization of the Weight Register File (WRF) and Input Register File (IRF). It shows how the register files are connected with a grouped DPPU with different number of computing groups.}}{227}{}\protected@file@percent }
\newlabel{fig:reg}{{5.9}{227}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3.1}Fault Detection with HyCA}{227}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Structure of the Fault-Detection Module.}}{228}{}\protected@file@percent }
\newlabel{fig:detection}{{5.10}{228}}[\bf Example\,]
\citation{meyer1989modeling}
\citation{liu2011resilient,li2008understanding,abdullah2020salvagednn,zhang2018analyzing}
\citation{zhang2018analyzing}
\citation{qian2016optimal}
\citation{mittal2020survey}
\citation{neggaz2018reliability}
\citation{ares2018dac}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Experiment Result Analysis}{229}{}\protected@file@percent }
\newlabel{sec:exp_result}{{5.2.4}{229}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.1}Experiment Setup}{229}{}\protected@file@percent }
\citation{samajdar2018scale}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Chip area under different redundancy approaches.}}{230}{}\protected@file@percent }
\newlabel{Circuit area}{{5.11}{230}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.2}Chip Area Overhead Comparison}{230}{}\protected@file@percent }
\newlabel{sec:chip-area}{{5.2.4.2}{230}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.3}Reliability Comparison}{231}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Fully functional probability of DLAs with different redundancy approaches.}}{232}{}\protected@file@percent }
\newlabel{fig:survival}{{5.12}{232}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Normalized computing power of DLAs with different redundancy approaches.}}{232}{}\protected@file@percent }
\newlabel{fig:available}{{5.13}{232}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Normalized performance of DLAs with different redundancy approaches}}{233}{}\protected@file@percent }
\newlabel{fig:ratio}{{5.14}{233}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Neural network runtime of the DLAs with different computing array sizes. Note that the row size of the computing arrays is fixed to be 32.}}{233}{}\protected@file@percent }
\newlabel{fig:model-performance}{{5.15}{233}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.4}Performance Comparison}{233}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Fully functional probability of the DLAs with different computing array sizes when they are protected with RR, CR, DR and HyCA respectively. Figure(a-d) are evaluated under the random fault distribution while Figure (e-h) are evaluated under the clustered fault distribution.}}{234}{}\protected@file@percent }
\newlabel{fig:scalability}{{5.16}{234}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.5}Redundancy Design Scalability Analysis}{234}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Fully functional probability of the DLAs configured with different DPPU sizes. The DPPUs with both the Unified structure and the Grouped structure are evaluated and compared.}}{236}{}\protected@file@percent }
\newlabel{fig:DPPU}{{5.17}{236}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.6}Fault Detection Analysis}{236}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces The proportion of the neural network layers of which the execution time can fully cover the fault detection of the entire 2-D computing array.}}{236}{}\protected@file@percent }
\newlabel{detection}{{5.1}{236}}[\bf Example\,]
\citation{7987496}
\citation{6725492}
\citation{6957074,Liu:2019:FTN:3287624.3288743}
\citation{7879109,8267883}
\citation{8624687}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Discussion}{237}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Online Fault Protection for ReRAM-based Deep Learning}{237}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}RRamedy Framework Overview}{237}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.1}Design Goals}{237}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.2}Target Fault Models}{237}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.3}Design Requirements}{238}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces The global flow of the RRAMedy framework.}}{239}{}\protected@file@percent }
\newlabel{fig:overview}{{5.18}{239}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Adversarial Example Testing on the Edge}{240}{}\protected@file@percent }
\citation{43405}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces The overview of Pause-and-Test mechanism (grey components can be adjusted by the cloud servers). }}{241}{}\protected@file@percent }
\newlabel{fig:ptest}{{5.19}{241}}[\bf Example\,]
\newlabel{equ:adv_generate}{{5.5}{241}}[\bf Example\,]
\citation{Wang2006VLSI}
\citation{7551274}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces A demonstration of adversarial example generation.}}{242}{}\protected@file@percent }
\newlabel{fig:advexample}{{5.20}{242}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces  The variations of confidence scores (a) when feeding the normal input into the normal network and faulty network and (b) when feeding the adversarial input into the normal network and faulty network.}}{242}{}\protected@file@percent }
\newlabel{fig:detection-mnist}{{5.21}{242}}[\bf Example\,]
\citation{7926952}
\citation{8013784}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Fault-masking Retraining on the Cloud}{243}{}\protected@file@percent }
\citation{NIPS2017_6749}
\citation{5482157}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Fault-masking retraining.}}{244}{}\protected@file@percent }
\newlabel{fig:faultmask}{{5.22}{244}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}In-Situ Model Remedy on the Edge}{244}{}\protected@file@percent }
\citation{10.1145/3287624.3287695}
\citation{44873}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces An overview of our in-situ faulty model retraining mechanism based on intermediate knowledge transfer from the golden model to the faulty model.}}{245}{}\protected@file@percent }
\newlabel{fig:insitutraining}{{5.23}{245}}[\bf Example\,]
\citation{DBLP:journals/corr/abs-1910-03723}
\citation{app9101966}
\newlabel{equ::MSE}{{5.10}{246}}[\bf Example\,]
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Knowledge Transfer Retraining Algorithm}}{248}{}\protected@file@percent }
\newlabel{algorithm}{{6}{248}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces Illustrations of the different backward propagation approaches including the BP algorithm, the IKTR algorithm, and the IKTR-P algorithm. The rectangles in the same color belong to the same training blocks. The arrow indicates the direction of the loss passing. $t$ represents the relative timestamp in each training iteration. $T$ represents the timestamp in the whole training phase.}}{248}{}\protected@file@percent }
\newlabel{fig:paralleltraining}{{5.24}{248}}[\bf Example\,]
\citation{7926952}
\citation{Li:2017:UEP:3126908.3126964}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Experiment Result Analysis}{249}{}\protected@file@percent }
\newlabel{Evaluations}{{5.3.5}{249}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.1}Experiment Setup}{249}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Benchmarks}}{249}{}\protected@file@percent }
\newlabel{tab:dataset}{{5.2}{249}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.2}Effectiveness of Adversarial Example Testing}{250}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces The $\varepsilon $ used in AET method}}{250}{}\protected@file@percent }
\newlabel{tab:disturbance}{{5.3}{250}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces Detection accuracy on SLC ReRAM on (a) MLP (b) LeNet (c) ConvNet network with the consideration of only permanent faults; only soft faults and both permanent faults and soft faults occurrence.}}{251}{}\protected@file@percent }
\newlabel{fig:mnist-slc}{{5.25}{251}}[\bf Example\,]
\citation{7551379}
\citation{7551379}
\citation{Xiangyu2011}
\@writefile{lof}{\contentsline {figure}{\numberline {5.26}{\ignorespaces Permanent fault detection accuracy with the implementation on MLC ReRAM of (a) MLP, (b) LeNet, (c) ConvNet network}}{252}{}\protected@file@percent }
\newlabel{fig:mlc-hard}{{5.26}{252}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.27}{\ignorespaces Soft fault detection accuracy with the implementation on MLC ReRAM of (a) MLP, (b) LeNet, (c) ConvNet network (The X-axis represents the resistance variations $\theta $).}}{253}{}\protected@file@percent }
\newlabel{fig:mlc-soft}{{5.27}{253}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.3}Effectiveness of Offline Retraining}{253}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.28}{\ignorespaces Fault detection accuracy, considering both permanent faults and soft faults on MLC ReRAM with (a) MLP, (b) LeNet, (c) ConvNet network (The X-axis represents the resistance variations $\theta $).}}{254}{}\protected@file@percent }
\newlabel{fig:mlc-hard-soft}{{5.28}{254}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.29}{\ignorespaces The performance speedups of our proposed on-line fault detection and diagnosis method.}}{255}{}\protected@file@percent }
\newlabel{fig:aetperformancecompare}{{5.29}{255}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.30}{\ignorespaces  Retrieved accuracy of fault-masking training with SLC ReRAM implementation ((a) MLP (c) LeNet (e) ConvNet network) and MLC ReRAM implementation ((b) MLP (d) LeNet (f) ConvNet network)}}{255}{}\protected@file@percent }
\newlabel{fig:retraining}{{5.30}{255}}[\bf Example\,]
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.4}Effectiveness of Online Retraining}{256}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.31}{\ignorespaces  The training block partition scheme used in this work. }}{256}{}\protected@file@percent }
\newlabel{fig:blockpartition}{{5.31}{256}}[\bf Example\,]
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Results of comparing the proposed IKTR and IKTR-P methods with traditional backpropagation algorithm (BP) and knowledge distillation algorithm (KD) on three benchmarks (LeNet, MLP, and ConvNet)}}{257}{}\protected@file@percent }
\newlabel{tab:IKTRresult}{{5.4}{257}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.32}{\ignorespaces Trade-offs between the recovered model accuracy, storage and timing costs.}}{258}{}\protected@file@percent }
\newlabel{fig:differenttrainingset}{{5.32}{258}}[\bf Example\,]
\@writefile{lof}{\contentsline {figure}{\numberline {5.33}{\ignorespaces Impact of fault positions on model accuracy. The red dots presented the recovered model accuracy with IKTR-P method. The black dots presented the faulty model accuracy. Boxes show median and 2nd and 3rd quartile of the faulty model accuracy.}}{259}{}\protected@file@percent }
\newlabel{fig:proportionalfaultinjectresult}{{5.33}{259}}[\bf Example\,]
\bibstyle{plain}
\bibdata{refs}
\bibcite{abdullah2020salvagednn}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Discussion}{260}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Summary}{260}{}\protected@file@percent }
\bibcite{DBLP:journals/corr/abs-1910-03723}{2}
\bibcite{Energy2003Aneesh}{3}
\bibcite{banerjee2019towards}{4}
\bibcite{A2012Chang}{5}
\bibcite{6725492}{6}
\bibcite{7926952}{7}
\bibcite{Chen2016Eyeriss}{8}
\bibcite{chen2014dadiannao}{9}
\bibcite{7551380}{10}
\bibcite{5726731}{11}
\bibcite{deng2009imagenet}{12}
\bibcite{deng2015retraining}{13}
\bibcite{impact2011dixit}{14}
\bibcite{Xiangyu2011}{15}
\bibcite{validation2019Ebert}{16}
\bibcite{esteva2019guide}{17}
\bibcite{fink2019deep}{18}
\bibcite{43405}{19}
\@writefile{toc}{\contentsline {section}{References}{261}{}\protected@file@percent }
\bibcite{8267883}{20}
\bibcite{error2018date}{21}
\bibcite{axtrain2018he}{22}
\bibcite{44873}{23}
\bibcite{horita2000fault}{24}
\bibcite{jenihhin2019challenges}{25}
\bibcite{jha2019ml}{26}
\bibcite{5482157}{27}
\bibcite{jouppi2017datacenter}{28}
\bibcite{energy2018kim}{29}
\bibcite{Li:2017:UEP:3126908.3126964}{30}
\bibcite{app9101966}{31}
\bibcite{li2019squeezing}{32}
\bibcite{li2008understanding}{33}
\bibcite{10.1145/3287624.3287695}{34}
\bibcite{li2020soft}{35}
\bibcite{ning2020ftt}{36}
\bibcite{7167198}{37}
\bibcite{liu2011resilient}{38}
\bibcite{8624687}{39}
\bibcite{Liu:2019:FTN:3287624.3288743}{40}
\bibcite{7551274}{41}
\bibcite{8715178}{42}
\bibcite{mahdiani2012relaxed}{43}
\bibcite{meyer1989modeling}{44}
\bibcite{mittal2020survey}{45}
\bibcite{neggaz2018reliability}{46}
\bibcite{6165062}{47}
\bibcite{ozen2019sanity}{48}
\bibcite{6957074}{49}
\bibcite{qian2016optimal}{50}
\bibcite{ares2018dac}{51}
\bibcite{reagen2016minerva}{52}
\bibcite{samajdar2018scale}{53}
\bibcite{7551379}{54}
\bibcite{7920854}{55}
\bibcite{stapper1983integrated}{56}
\bibcite{7879109}{57}
\bibcite{takanami2017built}{58}
\bibcite{takanami2012built}{59}
\bibcite{8013784}{60}
\bibcite{7987496}{61}
\bibcite{tzelepi2017human}{62}
\bibcite{Wang2006VLSI}{63}
\bibcite{wang2017resilience}{64}
\bibcite{NIPS2017_6749}{65}
\bibcite{6193402}{66}
\bibcite{8119491}{67}
\bibcite{xu2020hybrid}{68}
\bibcite{xu2020persistent}{69}
\bibcite{xu2021reliability}{70}
\bibcite{xu2019resilient}{71}
\bibcite{zhang2019fault}{72}
\bibcite{zhang2018analyzing}{73}
\bibcite{zhang2020sorting}{74}
\bibcite{zhao2020algorithm}{75}
\@setckpt{chapter5}{
\setcounter{page}{266}
\setcounter{equation}{13}
\setcounter{enumi}{6}
\setcounter{enumii}{2}
\setcounter{enumiii}{0}
\setcounter{enumiv}{75}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{33}
\setcounter{table}{4}
\setcounter{chapter}{5}
\setcounter{theorem}{0}
\setcounter{case}{0}
\setcounter{conjecture}{0}
\setcounter{corollary}{0}
\setcounter{definition}{0}
\setcounter{example}{0}
\setcounter{exercise}{0}
\setcounter{lemma}{0}
\setcounter{note}{0}
\setcounter{problem}{0}
\setcounter{property}{0}
\setcounter{proposition}{0}
\setcounter{question}{0}
\setcounter{solution}{0}
\setcounter{remark}{0}
\setcounter{prob}{0}
\setcounter{merk}{0}
\setcounter{endNonectr}{20}
\setcounter{currNonectr}{0}
\setcounter{currproofctr}{0}
\setcounter{endproofctr}{0}
\setcounter{proof}{0}
\setcounter{minitocdepth}{0}
\setcounter{@inst}{0}
\setcounter{@auth}{0}
\setcounter{auco}{0}
\setcounter{contribution}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{19}
\setcounter{algocfline}{6}
\setcounter{algocfproc}{6}
\setcounter{algocf}{6}
\setcounter{currexmpctr}{2}
\setcounter{endexmpctr}{11}
\setcounter{exmp}{0}
}
